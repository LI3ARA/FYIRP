{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f56eb32",
   "metadata": {},
   "source": [
    "- IRP ENV\n",
    "- This code is for extracting, text, images and convert pdfs to images and save in releavnt directories.\n",
    "- Texts are chunked and embeddings are created.\n",
    "- With meta data text are stored to given chromadb collection\n",
    "- meta data includes\n",
    "    - pdf name\n",
    "    - page number\n",
    "    - bounding box(empty, kept for further use)\n",
    "    - dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run in Jupyter or your environment)\n",
    "# !pip install langchain pymupdf chromadb nomic tiktoken pytesseract opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0e8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5f5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import NomicEmbeddings\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf321ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EMBEDDINGS via LM Studio\n",
    "# Custom wrapper to integrate LM Studio embeddings with LangChain\n",
    "class LMStudioEmbeddings(Embeddings):\n",
    "    def __init__(self, base_url=\"http://localhost:1235/v1\", api_key=\"lm-studio\", model=\"text-embedding-nomic-embed-text-v1.5\"):\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self.client.embeddings.create(input=[text.replace(\"\\n\", \" \")], model=self.model).data[0].embedding for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.client.embeddings.create(input=[text.replace(\"\\n\", \" \")], model=self.model).data[0].embedding\n",
    "\n",
    "# Use LM Studio Embeddings in LangChain\n",
    "embeddings = LMStudioEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae2a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT CHUNKER\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf6e79",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc65a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️. Function: Extract images from PDFs\n",
    "def extract_images(pdf_path, output_base_dir):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    output_dir = os.path.join(output_base_dir, \"images_extracted\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    image_paths = []\n",
    "    for page_num in range(len(doc)):\n",
    "        for img_index, img in enumerate(doc[page_num].get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            pix = fitz.Pixmap(doc, xref)\n",
    "            img_name = f\"{os.path.splitext(os.path.basename(pdf_path))[0]}_img_p{page_num+1}_{img_index}.png\"\n",
    "            img_path = os.path.join(output_dir, img_name)\n",
    "            if pix.n < 5:\n",
    "                pix.save(img_path)\n",
    "            else:\n",
    "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                pix.save(img_path)\n",
    "            image_paths.append(img_path)\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "\n",
    "# 2. Function: Load text from PDF using PyMuPDFLoader\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    loader = PyMuPDFLoader(pdf_path,\n",
    "                           mode = 'page') # extracts the whole pdf as a single langchain doc object\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "# 3. Function: Process a single PDF and return text chunks with metadata\n",
    "def process_pdf(pdf_path, dataset_name):\n",
    "    docs = extract_text_from_pdf(pdf_path)\n",
    "    all_chunks = []\n",
    "    for doc in docs:\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        for chunk in chunks:\n",
    "            chunk.metadata.update({\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"pdf_name\": os.path.basename(pdf_path),\n",
    "                \"page_number\": chunk.metadata.get(\"page\", \"\"),\n",
    "                \"bounding_box\": \"\",  # Not used here\n",
    "            })\n",
    "        all_chunks.extend(chunks)\n",
    "    return all_chunks\n",
    "\n",
    "# 4. Function: convert pdfs to images and save\n",
    "\n",
    "def save_pdf_pages_as_images(pdf_path, output_base_dir):\n",
    "    from pathlib import Path\n",
    "    \n",
    "    dataset_name = Path(pdf_path).parts[-3]\n",
    "    output_dir = os.path.join(output_base_dir, \"pdfs_to_images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    page_images = convert_from_path(pdf_path, dpi=300)\n",
    "\n",
    "    for i, img in enumerate(page_images):\n",
    "        img.save(os.path.join(output_dir, f\"{pdf_name}_page_{i+1}.png\"), \"PNG\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "895d8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Function: Process an entire dataset folder\n",
    "def process_dataset(dataset_name):\n",
    "    input_docs_path = os.path.join(DATA_FOLDER, dataset_name, \"docs\")\n",
    "    output_base_path = os.path.join(DATA_FOLDER_NEW, dataset_name)\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "    collection = Chroma(\n",
    "        collection_name=dataset_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=os.path.join(\"chromadb\", dataset_name)\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(input_docs_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(input_docs_path, filename)\n",
    "\n",
    "            # Save rendered pages\n",
    "            save_pdf_pages_as_images(pdf_path, output_base_path)\n",
    "\n",
    "            # Save embedded images\n",
    "            extract_images(pdf_path, output_base_path)\n",
    "\n",
    "            # Extract and store text chunks\n",
    "            chunks = process_pdf(pdf_path, dataset_name)\n",
    "            collection.add_documents(chunks)\n",
    "\n",
    "    collection.persist()\n",
    "    print(f\"[✓] Processed: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2abd7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f56b80",
   "metadata": {},
   "source": [
    "# For SPIQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e2a023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "dataset_name = \"spiqa\"\n",
    "DATA_FOLDER = \"../../../Data/VisDoM-main\"\n",
    "DATA_FOLDER_NEW = \"../../../Data/VisDOM\"\n",
    "CHROMA_DB_FOLDER = \"../../../chromadb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f249a",
   "metadata": {},
   "source": [
    "### Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1179d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f40fc",
   "metadata": {},
   "source": [
    "### Save PDF as Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16e36b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a61a7f1e2e4819a8f000b2370b8401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Processed: spiqa\n"
     ]
    }
   ],
   "source": [
    "input_docs_path = os.path.join(DATA_FOLDER, dataset_name, \"docs\")\n",
    "output_base_path = os.path.join(DATA_FOLDER_NEW, dataset_name)\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "\n",
    "for filename in tqdm(os.listdir(input_docs_path)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_docs_path, filename)\n",
    "\n",
    "        # Save rendered pages\n",
    "        save_pdf_pages_as_images(pdf_path, output_base_path)\n",
    "\n",
    "print(f\"[✓] Processed: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad1acf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183e8baa6a1f4d0e900107f59f2775ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Processed: scigraphvqa\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"scigraphvqa\"\n",
    "DATA_FOLDER = \"../../../Data/VisDoM-main\"\n",
    "DATA_FOLDER_NEW = \"../../../Data/VisDOM\"\n",
    "CHROMA_DB_FOLDER = \"../../../chromadb\"\n",
    "\n",
    "input_docs_path = os.path.join(DATA_FOLDER, dataset_name, \"docs\")\n",
    "output_base_path = os.path.join(DATA_FOLDER_NEW, dataset_name)\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(input_docs_path)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_docs_path, filename)\n",
    "\n",
    "        # Save rendered pages\n",
    "        save_pdf_pages_as_images(pdf_path, output_base_path)\n",
    "\n",
    "print(f\"[✓] Processed: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82bb649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ee6c4fbd2437fbdb6c792b1578edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Processed: slidevqa\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"slidevqa\"\n",
    "DATA_FOLDER = \"../../../Data/VisDoM-main\"\n",
    "DATA_FOLDER_NEW = \"../../../Data/VisDOM\"\n",
    "CHROMA_DB_FOLDER = \"../../../chromadb\"\n",
    "\n",
    "input_docs_path = os.path.join(DATA_FOLDER, dataset_name, \"docs\")\n",
    "output_base_path = os.path.join(DATA_FOLDER_NEW, dataset_name)\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(input_docs_path)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_docs_path, filename)\n",
    "\n",
    "        # Save rendered pages\n",
    "        save_pdf_pages_as_images(pdf_path, output_base_path)\n",
    "\n",
    "print(f\"[✓] Processed: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feta_tab, paper_tab, scigraphvqa, slidevqa, spiqa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRPenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
