{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7196f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SPIQA to LLaVA LoRA Fine-Tuning Pipeline (Colab Ready)\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install required libraries\n",
    "!pip install -q bitsandbytes accelerate peft transformers datasets huggingface_hub\n",
    "!git clone https://github.com/haotian-liu/LLaVA.git\n",
    "%cd LLaVA\n",
    "!pip install -e .\n",
    "\n",
    "# 3. Download SPIQA dataset from Hugging Face\n",
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(repo_id=\"google/spiqa\", repo_type=\"dataset\", local_dir='/content/spiqa')\n",
    "\n",
    "# 4. Unzip relevant data\n",
    "import zipfile, os\n",
    "\n",
    "zip_path = \"/content/spiqa/train_val/SPIQA_train_val_Images.zip\"\n",
    "extract_path = \"/content/spiqa_images\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# 5. Load and convert SPIQA_train.json to LLaVA format\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"/content/spiqa/train_val/SPIQA_train.json\", \"r\") as f:\n",
    "    spiqa_data = json.load(f)\n",
    "\n",
    "converted = []\n",
    "\n",
    "for entry in spiqa_data:\n",
    "    paper_id = entry[\"paper_id\"]\n",
    "    figures = {fig['id']: fig['file_path'] for fig in entry.get(\"figures\", [])}\n",
    "    for qa in entry.get(\"qa_pairs\", []):\n",
    "        fig_id = qa.get(\"figure_id\")\n",
    "        if not fig_id or fig_id not in figures:\n",
    "            continue\n",
    "        image_path = os.path.join(extract_path, figures[fig_id])\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        converted.append({\n",
    "            \"image\": image_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{qa['question']}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": qa[\"answer\"]\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "# 6. Save converted dataset to Google Drive\n",
    "output_path = \"/content/drive/MyDrive/SPIQA_train_converted.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(converted, f, indent=2)\n",
    "\n",
    "print(f\"Saved converted dataset to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
