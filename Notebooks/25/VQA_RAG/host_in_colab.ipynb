{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers fastapi uvicorn pyngrok\n",
    "!pip install \"git+https://github.com/huggingface/transformers.git\"  # for latest BLIP2 support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load vision model\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16 if device==\"cuda\" else torch.float32)\n",
    "model.to(device)\n",
    "\n",
    "def ask_question(image_path, question):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(image, question, return_tensors=\"pt\").to(device, torch.float16 if device==\"cuda\" else torch.float32)\n",
    "    out = model.generate(**inputs)\n",
    "    return processor.decode(out[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Fast api APP\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "import shutil\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/ask/\")\n",
    "async def ask(file: UploadFile = File(...), question: str = Form(...)):\n",
    "    with open(\"temp.jpg\", \"wb\") as f:\n",
    "        shutil.copyfileobj(file.file, f)\n",
    "    answer = ask_question(\"temp.jpg\", question)\n",
    "    return {\"answer\": answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunnel with ngrok\n",
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = ngrok.connect(8000)\n",
    "print(\"Your API is live at:\", public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run API server\n",
    "!uvicorn app:app --host 0.0.0.0 --port 8000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing locally\n",
    "# curl -X POST https://abc123.ngrok.io/ask/ \\\n",
    "#   -F \"file=@/path/to/image.jpg\" \\\n",
    "#   -F \"question=What is the person doing?\"\n",
    "\n",
    "\n",
    "# or \n",
    "import requests\n",
    "\n",
    "url = \"https://abc123.ngrok.io/ask/\"\n",
    "files = {'file': open('image.jpg', 'rb')}\n",
    "data = {'question': \"What is happening in this picture?\"}\n",
    "\n",
    "res = requests.post(url, files=files, data=data)\n",
    "print(res.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
